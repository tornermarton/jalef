{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is only for server (no colab func.)\n",
    "\n",
    "import os\n",
    "os.chdir(\"/app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "!find /app/data/ -name \"*_dataset_*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "!ls -l /app/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constatnts\n",
    "MAX_SEQ_LEN = 128\n",
    "MIN_SEQ_LEN = int(MAX_SEQ_LEN / 2)\n",
    "\n",
    "SOURCE = \"coursera\"\n",
    "EMBEDDING = \"bert\"\n",
    "N_INTENTS = 100\n",
    "BALANCED = True\n",
    "CUSTOM_PARAMETERS = dict()\n",
    "CUSTOM_PARAMETERS_AS_STRING = \"_\".join([str(key) + \"=\" + str(value) for key, value in CUSTOM_PARAMETERS])\n",
    "\n",
    "# Please fill these\n",
    "DATASET_PATH = \"/app/data/\"+SOURCE+\"_dataset_top\"+str(N_INTENTS)+\"/\"\n",
    "TEST_NAME = \"dataset={}_embedding={}{}{}intents={}\".format(\n",
    "    SOURCE, \n",
    "    EMBEDDING, \n",
    "    \"_balanced_\" if BALANCED else \"_\", \n",
    "    CUSTOM_PARAMETERS_AS_STRING + \"_\" if CUSTOM_PARAMETERS_AS_STRING != \"\", \n",
    "    N_INTENTS\n",
    ")\n",
    "\n",
    "PRETRAINED_MODEL_PATH = \"./models/bert/\"\n",
    "# modify if model changed to other H-XXXX!!!!\n",
    "OUTPUT_SIZE = 1024"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import json\n",
    "\n",
    "from jalef.preprocessing import BertPreprocessor\n",
    "from jalef.layers import Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(os.path.join(DATASET_PATH, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess texts\n",
    "bp = BertPreprocessor(max_sequence_length=MAX_SEQ_LEN, pretrained_model_path=PRETRAINED_MODEL_PATH)\n",
    "X_test, y_test = bp.fit_transform_classification(dataset[\"Text\"].values, dataset[\"Label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model from saved configs and load best weights\n",
    "with tf.keras.utils.CustomObjectScope({'Bert': Bert}):\n",
    "    with open(os.path.join(os.path.join(\"/app/logs/\", TEST_NAME), \"configs.json\")) as file:\n",
    "        json_str = json.load(file)\n",
    "        model = tf.keras.models.model_from_json(json_str)\n",
    "model.load_weights(os.path.join(os.path.join(\"/app/logs/\", TEST_NAME), \"weights.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds = model.predict(x=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "np.save(\n",
    "    os.path.join(os.path.join(\"/app/logs/\", TEST_NAME), \"predictions.npy\"), \n",
    "    preds\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
